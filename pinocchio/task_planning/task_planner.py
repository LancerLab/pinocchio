"""
Task planning module for Pinocchio multi-agent system.

This module provides intelligent task planning capabilities for coordinating
multiple agents in code generation and optimization workflows.
"""

import json
import logging
import os
from typing import Any, Dict, List, Optional

from pinocchio.config.config_manager import get_config_value

from ..data_models.task_planning import (
    AgentType,
    Task,
    TaskDependency,
    TaskPlan,
    TaskPriority,
)
from ..utils import parse_structured_output, safe_json_parse, validate_json_structure
from ..utils.verbose_logger import LogLevel, get_verbose_logger

logger = logging.getLogger(__name__)


class TaskPlanner:
    """Intelligent task planner for multi-agent coordination."""

    def __init__(
        self,
        llm_client: Optional[Any] = None,
        mode: str = "production",
        config: Optional[Any] = None,
    ):
        """
        Initialize task planner.

        Args:
            llm_client: LLM client for task planning
            mode: CLI mode (development/production). Development mode raises errors, production mode allows fallback
            config: Configuration object for planning settings
        """
        self.llm_client = llm_client
        self.mode = mode
        self.config = config
        logger.info(f"TaskPlanner initialized in {mode} mode")

    async def create_task_plan(
        self, user_request: str, session_id: Optional[str] = None
    ) -> TaskPlan:
        """
        Create a comprehensive task plan for user request.
        """
        verbose_logger = get_verbose_logger()
        verbose_logger.log(
            LogLevel.INFO,
            "task_planner",
            "Start creating task plan",
            {"user_request": user_request, "session_id": session_id},
        )
        logger.info(f"Creating task plan for request: {user_request[:50]}...")

        # Determine if workflow mode
        if self._is_workflow_mode():
            tasks = self._create_task_plan_from_workflow(user_request)
            plan = TaskPlan(
                plan_id=f"plan_{session_id or 'default'}",
                user_request=user_request,
                tasks=tasks,
                context={"planning_method": "fixed_workflow"},
            )
            verbose_logger.log(
                LogLevel.INFO,
                "task_planner",
                "Task plan created from workflow.json",
                {
                    "plan_id": plan.plan_id,
                    "task_count": len(tasks),
                    "tasks": [t.task_id for t in tasks],
                },
            )
            logger.info(f"Created task plan with {len(tasks)} tasks (workflow mode)")
            return plan

        # Default LLM decomposition
        tasks = await self._generate_tasks_with_llm(user_request)
        plan = TaskPlan(
            plan_id=f"plan_{session_id or 'default'}",
            user_request=user_request,
            tasks=tasks,
            context={"planning_method": "llm_decomposition"},
        )
        verbose_logger.log(
            LogLevel.INFO,
            "task_planner",
            "Task plan created",
            {
                "plan_id": plan.plan_id,
                "task_count": len(tasks),
                "tasks": [t.task_id for t in tasks],
            },
        )
        logger.info(f"Created task plan with {len(tasks)} tasks")
        return plan

    async def _generate_tasks_with_llm(self, user_request: str) -> List[Task]:
        """
        Generate tasks using LLM-based task decomposition.

        Args:
            user_request: User's request description

        Returns:
            List of tasks generated by LLM
        """
        verbose_logger = get_verbose_logger()
        verbose_logger.log(
            LogLevel.INFO,
            "task_planner",
            "Generating tasks with LLM",
            {"user_request": user_request},
        )

        if self.llm_client:
            try:
                # Use LLM for intelligent task decomposition
                prompt = self._build_task_decomposition_prompt(user_request)
                verbose_logger.log(
                    LogLevel.INFO,
                    "task_planner",
                    "LLM task decomposition prompt built",
                    {"prompt": prompt},
                )

                response = await self.llm_client.complete(prompt, agent_type="planner")
                verbose_logger.log(
                    LogLevel.INFO,
                    "task_planner",
                    "LLM task decomposition response received",
                    {"response": response},
                )

                tasks = self._parse_task_decomposition_response(response, user_request)
                verbose_logger.log(
                    LogLevel.INFO,
                    "task_planner",
                    "LLM task decomposition parsed",
                    {"task_count": len(tasks)},
                )

                return tasks

            except Exception as e:
                verbose_logger.log(
                    LogLevel.WARNING,
                    "task_planner",
                    "LLM task decomposition failed",
                    {"error": str(e)},
                )
                if self.mode == "development":
                    logger.error(
                        f"LLM task decomposition failed in development mode: {e}"
                    )
                    raise
                else:
                    verbose_logger.log(
                        LogLevel.INFO,
                        "task_planner",
                        "Using fallback task generation in production mode",
                    )
                    return self._generate_fallback_tasks(user_request)
        else:
            verbose_logger.log(
                LogLevel.WARNING, "task_planner", "No LLM client available"
            )
            if self.mode == "development":
                error_msg = (
                    "No LLM client available for task planning in development mode"
                )
                logger.error(error_msg)
                raise RuntimeError(error_msg)
            else:
                verbose_logger.log(
                    LogLevel.INFO,
                    "task_planner",
                    "Using fallback task generation in production mode",
                )
                return self._generate_fallback_tasks(user_request)

    def _build_task_decomposition_prompt(self, user_request: str) -> str:
        """Build prompt for LLM-based task decomposition."""

        # Get planning configuration
        planning_config = self._get_planning_config()
        max_rounds = planning_config.get("max_optimisation_rounds", 3)
        enable_optimizer = planning_config.get("enable_optimiser", True)

        # Build workflow description based on configuration
        workflow_desc = self._build_workflow_description(max_rounds, enable_optimizer)

        return f"""You are a Task Planning agent in the Pinocchio multi-agent system.
Your task is to decompose user requests into a sequence of tasks that can be executed by different agents.

Analyze the following user request and create a task plan:

Request: {user_request}

WORKFLOW CONFIGURATION:
{workflow_desc}

CRITICAL REQUIREMENTS:
1. You MUST respond with ONLY valid JSON format
2. Do NOT include any text before or after the JSON
3. Do NOT include markdown formatting, code blocks, or any other text
4. The response must be parseable as valid JSON
5. The number of tasks should be flexible based on the request complexity
6. The final task MUST be an evaluator task

Please provide a task plan in JSON format exactly as follows:

{{
    "agent_type": "planner",
    "success": true,
    "output": {{
        "tasks": [
            {{
                "task_id": "task_1",
                "agent_type": "generator",
                "description": "Generate initial code for the request",
                "dependencies": [],
                "priority": "critical",
        "requirements": {{
                    "code_type": "appropriate_for_request",
                    "optimization_level": "basic"
                }}
            }},
            {{
                "task_id": "task_2",
                "agent_type": "debugger",
                "description": "Debug and validate the generated code",
                "dependencies": ["task_1"],
                "priority": "high",
                "requirements": {{
                    "error_handling": true,
                    "validation": true
                }}
            }}
        ]
    }},
    "explanation": "Brief explanation of the task decomposition approach",
    "confidence": 0.95
}}

Task Decomposition Guidelines:
- Break down complex requests into logical steps
- Ensure each task has a clear, specific objective
- Consider dependencies between tasks (e.g., debug after generate)
- Use appropriate agent types for each task:
  * generator: Code generation tasks
  * debugger: Error detection and fixing tasks
  * optimizer: Performance optimization tasks (if enabled)
  * evaluator: Performance analysis and evaluation tasks (MUST be last)
- Set appropriate priorities (critical, high, medium, low)
- Include relevant requirements for each task
- The number of tasks should vary based on request complexity
- Always end with an evaluator task

FINAL REMINDER: Respond with ONLY the JSON object, no additional text, no markdown, no code blocks."""

    def _get_planning_config(self) -> Dict[str, Any]:
        """Get planning configuration from config object."""
        if self.config is None:
            return {
                "max_optimisation_rounds": 3,
                "enable_optimiser": True,
                "use_fixed_workflow": False,
            }

        try:
            # Try to get task_planning config
            if hasattr(self.config, "task_planning"):
                planning_config = self.config.task_planning
                if hasattr(planning_config, "model_dump"):
                    return planning_config.model_dump()
                else:
                    return planning_config
            elif hasattr(self.config, "get"):
                return self.config.get("task_planning", {})
            else:
                return {}
        except Exception as e:
            logger.warning(f"Failed to get planning config: {e}")
            return {
                "max_optimisation_rounds": 3,
                "enable_optimiser": True,
                "use_fixed_workflow": False,
            }

    def _build_workflow_description(
        self, max_rounds: int, enable_optimizer: bool
    ) -> str:
        """Build workflow description based on configuration."""
        if enable_optimizer:
            workflow = f"""
The workflow follows this pattern:
1. Generator -> Debugger -> Optimizer -> Evaluator (Round 1)
2. If optimization is needed, repeat: Generator -> Debugger -> Optimizer -> Evaluator (up to {max_rounds} rounds total)
3. Final step is always Evaluator

Maximum optimization rounds: {max_rounds}
Optimizer enabled: Yes
"""
        else:
            workflow = f"""
The workflow follows this pattern:
1. Generator -> Debugger -> Evaluator (Round 1)
2. If optimization is needed, repeat: Generator -> Debugger -> Evaluator (up to {max_rounds} rounds total)
3. Final step is always Evaluator

Maximum optimization rounds: {max_rounds}
Optimizer enabled: No
"""

        return workflow

    def _parse_task_decomposition_response(
        self, response: str, user_request: str
    ) -> List[Task]:
        """Parse LLM response for task decomposition."""
        try:
            # Use utils for JSON parsing
            parsed = safe_json_parse(response)
            if parsed is not None:
                # Check if this is the new format with output field
                if "output" in parsed and isinstance(parsed["output"], dict):
                    output = parsed["output"]
                    if "tasks" in output and isinstance(output["tasks"], list):
                        return self._create_tasks_from_llm_output(
                            output["tasks"], user_request
                        )
                else:
                    # Check if this is the old direct format
                    if "tasks" in parsed and isinstance(parsed["tasks"], list):
                        return self._create_tasks_from_llm_output(
                            parsed["tasks"], user_request
                        )
        except Exception as e:
            logger.warning(f"Failed to parse task decomposition response: {e}")

        # Fallback to basic task generation
        return self._generate_fallback_tasks(user_request)

    def _create_tasks_from_llm_output(
        self, task_definitions: List[Dict[str, Any]], user_request: str
    ) -> List[Task]:
        """Create Task objects from LLM output."""
        tasks = []

        for task_def in task_definitions:
            try:
                # Parse agent type
                agent_type_str = task_def.get("agent_type", "generator")
                agent_type = AgentType[agent_type_str.upper()]

                # Parse priority
                priority_str = task_def.get("priority", "medium")
                priority = TaskPriority[priority_str.upper()]

                # Create dependencies
                dependencies = []
                for dep_id in task_def.get("dependencies", []):
                    dependencies.append(
                        TaskDependency(task_id=dep_id, dependency_type="required")
                    )

                # Create task
                task = Task(
                    task_id=task_def["task_id"],
                    agent_type=agent_type,
                    task_description=task_def["description"],
                    requirements=task_def.get("requirements", {}),
                    optimization_goals=task_def.get("optimization_goals", []),
                    priority=priority,
                    dependencies=dependencies,
                    input_data={
                        "user_request": user_request,
                        "llm_generated": True,
                        "original_task_def": task_def,
                    },
                )

                tasks.append(task)

            except Exception as e:
                logger.warning(f"Failed to create task from LLM output: {e}")
                continue

        return tasks

    def _generate_fallback_tasks(self, user_request: str) -> List[Task]:
        """Generate fallback tasks when LLM fails."""
        verbose_logger = get_verbose_logger()
        verbose_logger.log(
            LogLevel.INFO,
            "task_planner",
            "Using fallback task generation",
            {"user_request": user_request},
        )

        # Create basic fallback tasks
        tasks = [
            Task(
                task_id="task_1",
                agent_type=AgentType.GENERATOR,
                task_description=f"Generate code for: {user_request}",
                requirements={},
                optimization_goals=["performance"],
                priority=TaskPriority.CRITICAL,
                dependencies=[],
                input_data={"user_request": user_request, "fallback": True},
            ),
            Task(
                task_id="task_2",
                agent_type=AgentType.DEBUGGER,
                task_description="Debug the generated code",
                requirements={"error_handling": True},
                optimization_goals=[],
                priority=TaskPriority.HIGH,
                dependencies=[
                    TaskDependency(task_id="task_1", dependency_type="required")
                ],
                input_data={"user_request": user_request, "fallback": True},
            ),
        ]

        return tasks

    def _is_workflow_mode(self) -> bool:
        """Determine if workflow mode is enabled."""
        # Can be determined by config/cli args/env vars, here simply use config.task_planning.use_fixed_workflow
        if self.config is not None:
            return bool(
                get_config_value(self.config, "task_planning.use_fixed_workflow", False)
            )
        return False

    def _create_task_plan_from_workflow(self, user_request: str) -> List[Task]:
        """Read fixed schedule from workflow.json and generate Task list."""
        workflow_path = os.path.join(os.getcwd(), "workflow.json")
        if not os.path.exists(workflow_path):
            raise FileNotFoundError(f"workflow.json not found at {workflow_path}")
        with open(workflow_path, "r", encoding="utf-8") as f:
            workflow_data = json.load(f)
        steps = workflow_data.get("workflow", [])
        tasks = []
        task_name_to_index = {step["task"]: idx for idx, step in enumerate(steps)}
        for idx, step in enumerate(steps):
            agent_type = AgentType[step["agent"].upper()]
            task_id = f"task_{idx+1}"
            dependencies = [
                TaskDependency(
                    task_id=f"task_{task_name_to_index[dep]+1}",
                    dependency_type="required",
                )
                for dep in step.get("depends_on", [])
                if dep in task_name_to_index
            ]
            task = Task(
                task_id=task_id,
                agent_type=agent_type,
                task_description=step.get("description", f"{step['agent']} step"),
                requirements=step.get("requirements", {}),
                optimization_goals=step.get("optimization_goals", []),
                priority=TaskPriority.MEDIUM,
                dependencies=dependencies,
                input_data={"user_request": user_request, "workflow_step": step},
            )
            tasks.append(task)
        return tasks

    def validate_plan(self, plan: TaskPlan) -> Dict[str, Any]:
        """
        Validate task plan for completeness and consistency.

        Args:
            plan: TaskPlan to validate

        Returns:
            Validation results
        """
        validation_results = {
            "valid": True,  # Keep backward compatibility
            "is_valid": True,
            "errors": [],
            "warnings": [],
            "task_count": len(plan.tasks),
            "dependency_issues": [],
            "issues": [],  # Keep backward compatibility
        }

        # Check for required tasks - only GENERATOR is absolutely required
        agent_types = [task.agent_type for task in plan.tasks]
        required_agents = [AgentType.GENERATOR]  # Only GENERATOR is required

        for agent_type in required_agents:
            if agent_type not in agent_types:
                validation_results["valid"] = False
                validation_results["is_valid"] = False
                error_msg = f"Missing required agent type: {agent_type}"
                validation_results["errors"].append(error_msg)
                validation_results["issues"].append(
                    error_msg
                )  # Keep backward compatibility

        # Check dependencies
        task_ids = {task.task_id for task in plan.tasks}
        for task in plan.tasks:
            for dependency in task.dependencies:
                if dependency.task_id not in task_ids:
                    error_msg = f"Task {task.task_id} depends on non-existent task {dependency.task_id}"
                    validation_results["dependency_issues"].append(error_msg)
                    validation_results["errors"].append(error_msg)
                    validation_results["issues"].append(
                        error_msg
                    )  # Keep backward compatibility
                elif dependency.task_id == task.task_id:
                    # Circular dependency
                    error_msg = f"Circular dependency in task {task.task_id}"
                    validation_results["dependency_issues"].append(error_msg)
                    validation_results["errors"].append(error_msg)
                    validation_results["issues"].append(
                        error_msg
                    )  # Keep backward compatibility

        if validation_results["dependency_issues"]:
            validation_results["valid"] = False
            validation_results["is_valid"] = False

        return validation_results
