# Workflows 模块设计文档（优化版）

## 概述

Workflows 模块采用简洁的设计，基于 Coordinator 进行工作流管理。不再使用复杂的状态机或消息队列，而是通过 Coordinator 直接协调各个 Agent 的执行顺序和依赖关系。

---

## 一、设计原则

### 1.1 简洁性原则
- 工作流由 Coordinator 直接管理
- 避免复杂的状态机和消息队列
- 清晰的执行顺序和依赖关系

### 1.2 可配置性原则
- 支持配置文件定义工作流
- 支持动态调整执行步骤
- 支持条件分支和循环

### 1.3 可观测性原则
- 完整的执行日志
- 清晰的进度反馈
- 详细的错误信息

---

## 二、核心架构

### 2.1 工作流定义

```python
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
from enum import Enum

class StepStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

class WorkflowStep(BaseModel):
    """工作流步骤定义"""
    step_id: str
    agent_type: str
    task_description: str
    dependencies: List[str] = []  # 依赖的步骤ID
    condition: Optional[str] = None  # 执行条件
    max_retries: int = 3
    timeout: int = 300  # 秒
    metadata: Dict[str, Any] = {}

class WorkflowPlan(BaseModel):
    """工作流计划"""
    workflow_id: str
    user_prompt: str
    steps: List[WorkflowStep]
    created_at: str
    estimated_duration: int = 0  # 预估执行时间（秒）
```

### 2.2 工作流执行器

```python
class WorkflowExecutor:
    """工作流执行器"""

    def __init__(self, coordinator: 'Coordinator'):
        self.coordinator = coordinator
        self.execution_log: List[Dict[str, Any]] = []

    async def execute_workflow(self, plan: WorkflowPlan) -> AsyncGenerator[str, None]:
        """执行工作流"""

        # 初始化执行状态
        step_status = {step.step_id: StepStatus.PENDING for step in plan.steps}
        step_results = {}

        yield f"开始执行工作流: {plan.workflow_id}"
        yield f"总步骤数: {len(plan.steps)}"

        # 执行步骤
        for step in plan.steps:
            # 检查依赖
            if not self._check_dependencies(step, step_status, step_results):
                step_status[step.step_id] = StepStatus.SKIPPED
                yield f"跳过步骤 {step.step_id}: 依赖未满足"
                continue

            # 检查条件
            if not self._check_condition(step, step_results):
                step_status[step.step_id] = StepStatus.SKIPPED
                yield f"跳过步骤 {step.step_id}: 条件不满足"
                continue

            # 执行步骤
            try:
                step_status[step.step_id] = StepStatus.RUNNING
                yield f"执行步骤 {step.step_id}: {step.agent_type}"

                result = await self._execute_step(step, step_results)
                step_results[step.step_id] = result
                step_status[step.step_id] = StepStatus.COMPLETED

                yield f"步骤 {step.step_id} 完成"

            except Exception as e:
                step_status[step.step_id] = StepStatus.FAILED
                yield f"步骤 {step.step_id} 失败: {str(e)}"

                # 检查是否需要停止工作流
                if self._should_stop_on_failure(step):
                    yield "工作流因关键步骤失败而停止"
                    break

        # 生成执行报告
        report = self._generate_execution_report(plan, step_status, step_results)
        yield f"工作流执行完成: {report['summary']}"

    def _check_dependencies(self, step: WorkflowStep, step_status: Dict[str, StepStatus], step_results: Dict[str, Any]) -> bool:
        """检查步骤依赖"""
        for dep_id in step.dependencies:
            if dep_id not in step_status or step_status[dep_id] != StepStatus.COMPLETED:
                return False
        return True

    def _check_condition(self, step: WorkflowStep, step_results: Dict[str, Any]) -> bool:
        """检查执行条件"""
        if not step.condition:
            return True

        # 简单的条件检查，可以根据需要扩展
        try:
            # 这里可以实现更复杂的条件解析
            return eval(step.condition, {"results": step_results})
        except:
            return True

    async def _execute_step(self, step: WorkflowStep, step_results: Dict[str, Any]) -> Dict[str, Any]:
        """执行单个步骤"""

        # 构建上下文
        context = {
            "step_id": step.step_id,
            "previous_results": step_results,
            "workflow_id": step.workflow_id if hasattr(step, 'workflow_id') else None
        }

        # 通过 Coordinator 执行
        result = await self.coordinator.execute_agent_step(
            agent_type=step.agent_type,
            task_description=step.task_description,
            context=context
        )

        return result

    def _should_stop_on_failure(self, step: WorkflowStep) -> bool:
        """检查失败时是否应该停止工作流"""
        return step.metadata.get("critical", False)

    def _generate_execution_report(self, plan: WorkflowPlan, step_status: Dict[str, StepStatus], step_results: Dict[str, Any]) -> Dict[str, Any]:
        """生成执行报告"""
        completed = sum(1 for status in step_status.values() if status == StepStatus.COMPLETED)
        failed = sum(1 for status in step_status.values() if status == StepStatus.FAILED)
        skipped = sum(1 for status in step_status.values() if status == StepStatus.SKIPPED)

        return {
            "workflow_id": plan.workflow_id,
            "total_steps": len(plan.steps),
            "completed": completed,
            "failed": failed,
            "skipped": skipped,
            "success_rate": completed / len(plan.steps) if plan.steps else 0,
            "summary": f"完成 {completed}/{len(plan.steps)} 步骤"
        }
```

### 2.3 工作流规划器

```python
class WorkflowPlanner:
    """工作流规划器"""

    def __init__(self):
        self.templates = self._load_workflow_templates()

    async def create_plan(self, user_prompt: str) -> WorkflowPlan:
        """根据用户输入创建工作流计划"""

        # 分析用户需求
        requirements = self._analyze_requirements(user_prompt)

        # 生成步骤
        steps = self._generate_steps(requirements)

        # 计算依赖关系
        steps = self._resolve_dependencies(steps)

        # 估算执行时间
        estimated_duration = self._estimate_duration(steps)

        return WorkflowPlan(
            workflow_id=f"workflow_{uuid.uuid4().hex[:8]}",
            user_prompt=user_prompt,
            steps=steps,
            created_at=datetime.utcnow().isoformat(),
            estimated_duration=estimated_duration
        )

    def _analyze_requirements(self, user_prompt: str) -> Dict[str, Any]:
        """分析用户需求"""
        # 这里可以使用简单的关键词匹配或调用LLM进行分析
        requirements = {
            "needs_generation": "生成" in user_prompt or "编写" in user_prompt,
            "needs_debugging": "调试" in user_prompt or "修复" in user_prompt,
            "needs_optimization": "优化" in user_prompt or "性能" in user_prompt,
            "needs_evaluation": "评估" in user_prompt or "测试" in user_prompt,
            "complexity": self._assess_complexity(user_prompt)
        }

        return requirements

    def _generate_steps(self, requirements: Dict[str, Any]) -> List[WorkflowStep]:
        """生成工作流步骤"""
        steps = []
        step_id = 1

        # 代码生成步骤
        if requirements["needs_generation"]:
            steps.append(WorkflowStep(
                step_id=f"step_{step_id}",
                agent_type="generator",
                task_description="根据用户需求生成Choreo DSL算子代码",
                metadata={"critical": True}
            ))
            step_id += 1

        # 代码调试步骤
        if requirements["needs_debugging"]:
            steps.append(WorkflowStep(
                step_id=f"step_{step_id}",
                agent_type="debugger",
                task_description="调试和修复代码中的问题",
                dependencies=[f"step_{step_id-1}"] if step_id > 1 else [],
                metadata={"critical": False}
            ))
            step_id += 1

        # 代码优化步骤
        if requirements["needs_optimization"]:
            steps.append(WorkflowStep(
                step_id=f"step_{step_id}",
                agent_type="optimizer",
                task_description="优化代码性能和资源使用",
                dependencies=[f"step_{step_id-1}"] if step_id > 1 else [],
                metadata={"critical": False}
            ))
            step_id += 1

        # 代码评估步骤
        if requirements["needs_evaluation"]:
            steps.append(WorkflowStep(
                step_id=f"step_{step_id}",
                agent_type="evaluator",
                task_description="评估代码质量和性能",
                dependencies=[f"step_{step_id-1}"] if step_id > 1 else [],
                metadata={"critical": False}
            ))

        return steps

    def _resolve_dependencies(self, steps: List[WorkflowStep]) -> List[WorkflowStep]:
        """解析步骤间的依赖关系"""
        # 这里可以实现更复杂的依赖解析逻辑
        return steps

    def _estimate_duration(self, steps: List[WorkflowStep]) -> int:
        """估算执行时间"""
        # 简单的估算：每个步骤平均30秒
        return len(steps) * 30

    def _assess_complexity(self, user_prompt: str) -> str:
        """评估任务复杂度"""
        if any(word in user_prompt for word in ["复杂", "高级", "优化"]):
            return "high"
        elif any(word in user_prompt for word in ["简单", "基础"]):
            return "low"
        else:
            return "medium"
```

---

## 三、工作流模板

### 3.1 基础工作流模板

```json
{
  "templates": {
    "simple_generation": {
      "name": "简单代码生成",
      "description": "仅生成代码，不进行调试和优化",
      "steps": [
        {
          "step_id": "step_1",
          "agent_type": "generator",
          "task_description": "根据用户需求生成Choreo DSL算子代码",
          "dependencies": [],
          "critical": true
        }
      ]
    },
    "full_development": {
      "name": "完整开发流程",
      "description": "生成、调试、优化、评估的完整流程",
      "steps": [
        {
          "step_id": "step_1",
          "agent_type": "generator",
          "task_description": "根据用户需求生成Choreo DSL算子代码",
          "dependencies": [],
          "critical": true
        },
        {
          "step_id": "step_2",
          "agent_type": "debugger",
          "task_description": "调试和修复代码中的问题",
          "dependencies": ["step_1"],
          "critical": false
        },
        {
          "step_id": "step_3",
          "agent_type": "optimizer",
          "task_description": "优化代码性能和资源使用",
          "dependencies": ["step_2"],
          "critical": false
        },
        {
          "step_id": "step_4",
          "agent_type": "evaluator",
          "task_description": "评估代码质量和性能",
          "dependencies": ["step_3"],
          "critical": false
        }
      ]
    },
    "debug_and_fix": {
      "name": "调试修复流程",
      "description": "针对已有代码进行调试和修复",
      "steps": [
        {
          "step_id": "step_1",
          "agent_type": "debugger",
          "task_description": "分析代码问题并提供修复方案",
          "dependencies": [],
          "critical": true
        },
        {
          "step_id": "step_2",
          "agent_type": "evaluator",
          "task_description": "评估修复后的代码质量",
          "dependencies": ["step_1"],
          "critical": false
        }
      ]
    }
  }
}
```

### 3.2 条件工作流

```python
class ConditionalWorkflow:
    """条件工作流"""

    def __init__(self):
        self.conditions = {
            "has_errors": lambda results: any("error" in str(result).lower() for result in results.values()),
            "needs_optimization": lambda results: any("performance" in str(result).lower() for result in results.values()),
            "quality_low": lambda results: any("score" in str(result) and "score" in str(result) and int(str(result).split("score")[1].split()[0]) < 70 for result in results.values())
        }

    def create_conditional_plan(self, user_prompt: str) -> WorkflowPlan:
        """创建条件工作流计划"""
        base_steps = [
            WorkflowStep(
                step_id="step_1",
                agent_type="generator",
                task_description="生成代码",
                dependencies=[],
                critical=True
            ),
            WorkflowStep(
                step_id="step_2",
                agent_type="debugger",
                task_description="调试代码",
                dependencies=["step_1"],
                condition="has_errors",
                critical=False
            ),
            WorkflowStep(
                step_id="step_3",
                agent_type="optimizer",
                task_description="优化代码",
                dependencies=["step_2"],
                condition="needs_optimization",
                critical=False
            ),
            WorkflowStep(
                step_id="step_4",
                agent_type="evaluator",
                task_description="评估代码",
                dependencies=["step_3"],
                critical=False
            )
        ]

        return WorkflowPlan(
            workflow_id=f"conditional_{uuid.uuid4().hex[:8]}",
            user_prompt=user_prompt,
            steps=base_steps,
            created_at=datetime.utcnow().isoformat()
        )
```

---

## 四、与Coordinator的集成

### 4.1 Coordinator扩展

```python
class Coordinator:
    """扩展的Coordinator，支持工作流管理"""

    def __init__(self):
        self.prompt_manager = PromptManager()
        self.memory_manager = MemoryManager()
        self.knowledge_manager = KnowledgeManager()
        self.agent_manager = AgentManager()
        self.workflow_planner = WorkflowPlanner()
        self.workflow_executor = WorkflowExecutor(self)
        self.session = None

    async def process_user_request(self, user_prompt: str) -> AsyncGenerator[str, None]:
        """处理用户请求"""

        # 创建session
        self.session = SessionLogger(user_prompt)
        yield self.session.log_summary("Session started")

        # 创建工作流计划
        plan = await self.workflow_planner.create_plan(user_prompt)
        yield self.session.log_summary(f"Workflow plan created: {len(plan.steps)} steps")

        # 执行工作流
        async for message in self.workflow_executor.execute_workflow(plan):
            yield self.session.log_summary(message)

        yield self.session.log_summary("Session completed")

    async def execute_agent_step(self, agent_type: str, task_description: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """执行单个Agent步骤"""

        # 获取综合prompt
        prompt = await self.prompt_manager.get_comprehensive_prompt(
            agent_type=agent_type,
            task_description=task_description,
            context=context
        )

        # 执行agent
        result = await self.agent_manager.execute_agent(agent_type, prompt)

        # 记录到session
        if self.session:
            self.session.log_communication(
                step_id=context.get("step_id", "unknown"),
                agent_type=agent_type,
                prompt=prompt,
                result=result.dict()
            )

        return result.dict()
```

---

## 五、配置管理

### 5.1 工作流配置

```json
{
  "workflows": {
    "default_template": "full_development",
    "timeout": {
      "default": 300,
      "generator": 600,
      "debugger": 300,
      "optimizer": 450,
      "evaluator": 300
    },
    "retry": {
      "max_attempts": 3,
      "backoff_factor": 2
    },
    "parallel": {
      "enabled": false,
      "max_concurrent": 2
    }
  }
}
```

### 5.2 条件配置

```json
{
  "conditions": {
    "has_errors": {
      "enabled": true,
      "keywords": ["error", "exception", "failed"],
      "threshold": 0.1
    },
    "needs_optimization": {
      "enabled": true,
      "keywords": ["slow", "performance", "optimize"],
      "threshold": 0.3
    },
    "quality_low": {
      "enabled": true,
      "score_threshold": 70,
      "metric": "overall_score"
    }
  }
}
```

---

## 六、错误处理

### 6.1 工作流错误类型

```python
class WorkflowError(Exception):
    """工作流基础错误"""
    pass

class WorkflowExecutionError(WorkflowError):
    """工作流执行错误"""
    pass

class WorkflowTimeoutError(WorkflowError):
    """工作流超时错误"""
    pass

class WorkflowDependencyError(WorkflowError):
    """工作流依赖错误"""
    pass
```

### 6.2 错误恢复策略

```python
class WorkflowErrorHandler:
    """工作流错误处理器"""

    def __init__(self):
        self.recovery_strategies = {
            "timeout": self._handle_timeout,
            "dependency": self._handle_dependency_error,
            "agent_failure": self._handle_agent_failure,
            "critical_failure": self._handle_critical_failure
        }

    def handle_error(self, error: Exception, step: WorkflowStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """处理工作流错误"""
        error_type = self._classify_error(error)

        if error_type in self.recovery_strategies:
            return self.recovery_strategies[error_type](error, step, context)
        else:
            return self._handle_unknown_error(error, step, context)

    def _handle_timeout(self, error: Exception, step: WorkflowStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """处理超时错误"""
        return {
            "success": False,
            "error_type": "timeout",
            "error_message": f"步骤 {step.step_id} 执行超时",
            "retry_available": True
        }

    def _handle_dependency_error(self, error: Exception, step: WorkflowStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """处理依赖错误"""
        return {
            "success": False,
            "error_type": "dependency",
            "error_message": f"步骤 {step.step_id} 的依赖未满足",
            "retry_available": False
        }

    def _handle_agent_failure(self, error: Exception, step: WorkflowStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """处理Agent失败"""
        return {
            "success": False,
            "error_type": "agent_failure",
            "error_message": f"Agent {step.agent_type} 执行失败",
            "retry_available": True
        }

    def _handle_critical_failure(self, error: Exception, step: WorkflowStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """处理关键错误"""
        return {
            "success": False,
            "error_type": "critical_failure",
            "error_message": f"关键步骤 {step.step_id} 失败，工作流停止",
            "retry_available": False,
            "stop_workflow": True
        }
```

---

## 七、测试策略

### 7.1 单元测试

```python
import pytest
from unittest.mock import AsyncMock, MagicMock

class TestWorkflowExecutor:
    """工作流执行器测试"""

    @pytest.fixture
    def mock_coordinator(self):
        coordinator = AsyncMock()
        coordinator.execute_agent_step.return_value = {"success": True, "output": "test"}
        return coordinator

    @pytest.fixture
    def executor(self, mock_coordinator):
        return WorkflowExecutor(mock_coordinator)

    @pytest.fixture
    def simple_plan(self):
        return WorkflowPlan(
            workflow_id="test_workflow",
            user_prompt="test prompt",
            steps=[
                WorkflowStep(
                    step_id="step_1",
                    agent_type="generator",
                    task_description="test task",
                    dependencies=[]
                )
            ],
            created_at="2023-01-01T00:00:00Z"
        )

    @pytest.mark.asyncio
    async def test_execute_workflow_success(self, executor, simple_plan):
        """测试工作流成功执行"""
        messages = []
        async for message in executor.execute_workflow(simple_plan):
            messages.append(message)

        assert len(messages) > 0
        assert "开始执行工作流" in messages[0]
        assert "工作流执行完成" in messages[-1]

    @pytest.mark.asyncio
    async def test_execute_workflow_with_dependencies(self, executor, mock_coordinator):
        """测试带依赖的工作流执行"""
        plan = WorkflowPlan(
            workflow_id="test_workflow",
            user_prompt="test prompt",
            steps=[
                WorkflowStep(
                    step_id="step_1",
                    agent_type="generator",
                    task_description="generate code",
                    dependencies=[]
                ),
                WorkflowStep(
                    step_id="step_2",
                    agent_type="debugger",
                    task_description="debug code",
                    dependencies=["step_1"]
                )
            ],
            created_at="2023-01-01T00:00:00Z"
        )

        messages = []
        async for message in executor.execute_workflow(plan):
            messages.append(message)

        # 验证执行顺序
        step_1_index = next(i for i, msg in enumerate(messages) if "step_1" in msg and "执行" in msg)
        step_2_index = next(i for i, msg in enumerate(messages) if "step_2" in msg and "执行" in msg)

        assert step_1_index < step_2_index
```

### 7.2 集成测试

```python
class TestWorkflowIntegration:
    """工作流集成测试"""

    @pytest.mark.asyncio
    async def test_full_workflow_execution(self):
        """测试完整工作流执行"""
        coordinator = Coordinator()
        planner = WorkflowPlanner()
        executor = WorkflowExecutor(coordinator)

        # 创建计划
        plan = await planner.create_plan("编写一个conv2d算子")

        # 执行工作流
        messages = []
        async for message in executor.execute_workflow(plan):
            messages.append(message)

        # 验证结果
        assert len(messages) > 0
        assert any("完成" in msg for msg in messages)
```

---

## 八、性能优化

### 8.1 并行执行

```python
class ParallelWorkflowExecutor(WorkflowExecutor):
    """支持并行执行的工作流执行器"""

    async def execute_workflow_parallel(self, plan: WorkflowPlan, max_concurrent: int = 2) -> AsyncGenerator[str, None]:
        """并行执行工作流"""

        # 构建依赖图
        dependency_graph = self._build_dependency_graph(plan.steps)

        # 找到可并行执行的步骤
        ready_steps = [step for step in plan.steps if not step.dependencies]
        completed_steps = set()

        while ready_steps:
            # 选择要执行的步骤
            to_execute = ready_steps[:max_concurrent]
            ready_steps = ready_steps[max_concurrent:]

            # 并行执行
            tasks = [self._execute_step_async(step) for step in to_execute]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # 处理结果
            for step, result in zip(to_execute, results):
                if isinstance(result, Exception):
                    yield f"步骤 {step.step_id} 失败: {result}"
                else:
                    completed_steps.add(step.step_id)
                    yield f"步骤 {step.step_id} 完成"

            # 更新就绪步骤
            ready_steps.extend(self._get_ready_steps(plan.steps, completed_steps, dependency_graph))
```

### 8.2 缓存机制

```python
class CachedWorkflowExecutor(WorkflowExecutor):
    """带缓存的工作流执行器"""

    def __init__(self, coordinator: 'Coordinator'):
        super().__init__(coordinator)
        self.cache = {}

    async def _execute_step(self, step: WorkflowStep, step_results: Dict[str, Any]) -> Dict[str, Any]:
        """执行步骤（带缓存）"""

        # 生成缓存键
        cache_key = self._generate_cache_key(step, step_results)

        # 检查缓存
        if cache_key in self.cache:
            return self.cache[cache_key]

        # 执行步骤
        result = await super()._execute_step(step, step_results)

        # 缓存结果
        self.cache[cache_key] = result

        return result

    def _generate_cache_key(self, step: WorkflowStep, step_results: Dict[str, Any]) -> str:
        """生成缓存键"""
        import hashlib

        # 基于步骤配置和输入生成哈希
        key_data = {
            "step_id": step.step_id,
            "agent_type": step.agent_type,
            "task_description": step.task_description,
            "input_hash": hashlib.md5(str(step_results).encode()).hexdigest()
        }

        return hashlib.md5(str(key_data).encode()).hexdigest()
```

---

## 九、总结

这个优化后的 Workflows 模块设计具有以下特点：

1. **简洁明了**：基于 Coordinator 的直接管理，避免复杂的消息队列
2. **易于理解**：清晰的工作流定义和执行逻辑
3. **可配置性强**：支持模板和条件配置
4. **错误处理完善**：多种错误类型和恢复策略
5. **性能友好**：支持并行执行和缓存机制

该设计专注于核心功能，通过 Coordinator 统一管理，为后续的功能扩展奠定了良好的基础。


## Conclusion

The Workflows Module provides a flexible and robust framework for orchestrating multi-agent tasks in the Pinocchio system. By abstracting the coordination logic into workflow definitions, it enables complex agent interactions while maintaining clear separation of concerns. The lightweight message queue facilitates efficient inter-agent communication, and the task-based execution model supports both sequential and conditional execution paths.
